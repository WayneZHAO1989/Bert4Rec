{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfd7587-5291-4110-bbd3-b5449d8881ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from collections import deque\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675b7595-61e3-4d6c-901d-21253b55deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config import args\n",
    "from dataloader import BertDataloader, BertTrainDataset, BertEvalDataset\n",
    "from utils import recalls_and_ndcgs_for_ks, AverageMeterSet\n",
    "from model import BERTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37afba7-ae1d-4e46-a4db-1a85249d2900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc127b7-9eab-411c-a091-d547effffaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dataloader\n",
    "def load_data(filePath, min_rating=0, min_sc=0, min_uc=5):\n",
    "    \"\"\"M1-1M\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filePath, sep='::', header=None)\n",
    "    df.columns = ['uid', 'sid', 'rating', 'timestamp']\n",
    "    \n",
    "    # Turning into implicit ratings\n",
    "    df = df[df['rating'] >= min_rating]\n",
    "    \n",
    "    # Filtering triplets\n",
    "    if min_sc > 0:\n",
    "        item_sizes = df.groupby('sid').size()\n",
    "        good_items = item_sizes.index[item_sizes >= min_sc]\n",
    "        df = df[df['sid'].isin(good_items)]\n",
    "    \n",
    "    if min_uc > 0:\n",
    "        user_sizes = df.groupby('uid').size()\n",
    "        good_users = user_sizes.index[user_sizes >= min_uc]\n",
    "        df = df[df['uid'].isin(good_users)]\n",
    "    \n",
    "    # Densifying index\n",
    "    umap = {u: i for i, u in enumerate(set(df['uid']))}\n",
    "    smap = {s: i for i, s in enumerate(set(df['sid']))}\n",
    "    df['uid'] = df['uid'].map(umap)\n",
    "    df['sid'] = df['sid'].map(smap)\n",
    "    \n",
    "    # Split into train/val/test\n",
    "    user_group = df.groupby('uid')\n",
    "    user2items = user_group.apply(lambda d: list(d.sort_values(by='timestamp')['sid']))\n",
    "    train, val, test = {}, {}, {}\n",
    "    for user in range(len(umap)):\n",
    "        items = user2items[user]\n",
    "        train[user], val[user], test[user] = items[:-2], items[-2:-1], items[-1:]\n",
    "    \n",
    "    return df, umap, smap, train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca31133-7698-4464-8eee-ebd3a579390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "\n",
    "def calculate_loss(batch):\n",
    "    seqs, labels = batch\n",
    "    logits = model(seqs)  # B x T x V\n",
    "    logits = logits.view(-1, logits.size(-1))  # (B*T) x V\n",
    "    labels = labels.view(-1)  # B*T\n",
    "    loss = ce(logits, labels)\n",
    "    return loss\n",
    "\n",
    "def calculate_metrics(batch, metric_ks=args.metric_ks):\n",
    "    seqs, candidates, labels = batch\n",
    "    scores = model(seqs)  # B x T x V\n",
    "    scores = scores[:, -1, :]  # B x V\n",
    "    scores = scores.gather(1, candidates)  # B x C\n",
    "\n",
    "    metrics = recalls_and_ndcgs_for_ks(scores, labels, metric_ks)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b6674-326f-4fc3-a325-2db34611810c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1df25-ce6d-4e21-8a20-ce35dcba9c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c86696-91fa-4aac-b3fe-ce16a5872ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "_, umap, smap, train, val, test = load_data(args.data_path, args.min_rating, args.min_sc, args.min_uc)\n",
    "\n",
    "args.num_items = len(smap)\n",
    "\n",
    "dataloader = BertDataloader(args, umap, smap, train, val, test, './')\n",
    "train_dataloader, val_dataloader, test_dataloader = dataloader.get_pytorch_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590016b7-f42a-4d19-bd34-bc2c77966b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model init\n",
    "model = BERTModel(args)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.decay_step, gamma=args.gamma)\n",
    "ce = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fedf2d-6d32-4308-8d77-8f8d141aa331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d796f5-7e38-47eb-a78b-301317c17161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67da0dde-351b-4bd4-ae04-2f393b2fb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_eval(mode):\n",
    "    model.eval()\n",
    "\n",
    "    average_meter_set = AverageMeterSet()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if mode=='val':\n",
    "            tqdm_dataloader = tqdm(val_dataloader)\n",
    "        else:\n",
    "            tqdm_dataloader = tqdm(test_dataloader)\n",
    "            \n",
    "        for batch_idx, batch in enumerate(tqdm_dataloader):\n",
    "            batch = [x.to(args.device) for x in batch]\n",
    "            metrics = calculate_metrics(batch)\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                average_meter_set.update(k, v)\n",
    "            description_metrics = ['NDCG@%d' % k for k in args.metric_ks[:3]] +\\\n",
    "                                  ['Recall@%d' % k for k in args.metric_ks[:3]]\n",
    "            description = 'Val: ' + ', '.join(s + ' {:.3f}' for s in description_metrics)\n",
    "            description = description.format(*(average_meter_set[k].avg for k in description_metrics))\n",
    "            tqdm_dataloader.set_description(description)\n",
    "            \n",
    "\n",
    "\n",
    "def train_one_epoch( epoch, accum_iter):\n",
    "\n",
    "    model.train()\n",
    "    lr_scheduler.step()\n",
    "    loss_history = deque(maxlen=200)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(train_dataloader, dynamic_ncols=True) ):\n",
    "        batch_size = batch[0].size(0)\n",
    "        batch = [x.to(args.device) for x in batch]\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss = calculate_loss(batch)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "        loss_history.append(loss.tolist())\n",
    "\n",
    "    torch.save(model, \"model_checkpoint_epoch_{}.pt\".format( str(epoch).zfill(2) ))\n",
    "    print(\"Epoch: \", epoch, \", Loss:\", np.mean(loss_history))\n",
    "\n",
    "    return accum_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debbad7-473c-4b4f-99b8-55bd1c390607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12288374-557e-4b2d-a656-263272c4aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfedf3-aded-40e1-8df8-a7147bd8f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_iter = 0\n",
    "run_eval(mode='val')\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    accum_iter = train_one_epoch(epoch, accum_iter)\n",
    "    run_eval(mode='val')\n",
    "\n",
    "run_eval(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8c65c-2ff0-415c-a39e-568cf3475d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21b8df-7855-4882-9b7f-c49daed7f937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e08d6-fb60-4147-811b-6abf37b62c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0812655-eab2-4a96-8b53-079b6336b11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3890df8-e74c-4574-b439-15200a1d9040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed108eb-11e9-41d8-8937-901a7ab4c202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24826656-bf40-4480-a883-ca08d0c2c518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
